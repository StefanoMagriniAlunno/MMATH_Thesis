{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# genero i dati:\n",
        "N = 6\n",
        "n_points = [20, 20, 20, 30, 30, 40]\n",
        "noise_w = 0.3\n",
        "# scelgo casualmente in [-10,10]x[-10,10] N centroidi a valori reali\n",
        "centroids = np.random.rand(N, 2) * 20 - 10\n",
        "# stabilisco delle varianze casuali per questi centroidi tra [0.5, 2]\n",
        "variances = np.random.rand(N) * 1.5 + 0.5\n",
        "# stabilisco il numero di punti per ogni cluster\n",
        "# genero i punti\n",
        "data = [np.random.randn(n, 2) * variances[i] + centroids[i] for i, n in enumerate(n_points)]\n",
        "\n",
        "# inserisco del rumore: aggiungo dei punti uniformemente distribuiti in [-15,15]*[-15,15]\n",
        "noise = np.random.rand(int(noise_w*sum(n_points)), 2) * 30 - 15\n",
        "\n",
        "# plotto tutto\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "for i in range(N):\n",
        "    ax.scatter(data[i][:, 0], data[i][:, 1], label='Cluster %d' % i)\n",
        "\n",
        "ax.scatter(noise[:, 0], noise[:, 1], label='Noise', c='black', alpha=0.5)\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KMeans algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# eseguo il classico KMeans\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "fused_data = np.concatenate(data + [noise])\n",
        "kmeans = KMeans(n_clusters=N, init='k-means++', max_iter=1000)\n",
        "kmeans.fit(fused_data)\n",
        "labels = kmeans.predict(fused_data)\n",
        "\n",
        "# plotto i risultati:\n",
        "# i centroidi sono indicati con una x e i dati con dei cerchi\n",
        "# il colore di un cluster \u00e8 dettato dal label stimato con kmeans\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(N):\n",
        "    plt.scatter(fused_data[labels == i][:, 0], fused_data[labels == i][:, 1], label='Cluster %d' % i)\n",
        "    plt.scatter(kmeans.cluster_centers_[i][0], kmeans.cluster_centers_[i][1], marker='x', s=100, c='black')\n",
        "\n",
        "# la legenda la voglio fuori dal plot\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gaussian Mixture Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# eseguo il Gaussian Mixture Model\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from matplotlib.patches import Ellipse\n",
        "\n",
        "n_clusters = 6\n",
        "gmm = GaussianMixture(n_components=n_clusters, covariance_type='full', init_params='kmeans', max_iter=1000, tol=1e-6)\n",
        "\n",
        "gmm.fit(fused_data)\n",
        "labels = gmm.predict(fused_data)\n",
        "\n",
        "# plotto i risultati:\n",
        "# i centroidi sono indicati con una x e i dati con dei cerchi\n",
        "# il colore di un cluster \u00e8 dettato dal label stimato con gmm\n",
        "# indico con un'ellisse la covarianza del cluster\n",
        "# indico il peso del cluster con un numero vicino al centroide\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(N):\n",
        "    plt.scatter(fused_data[labels == i][:, 0], fused_data[labels == i][:, 1], label='Cluster %d' % i)\n",
        "    plt.scatter(gmm.means_[i][0], gmm.means_[i][1], marker='x', s=100, c='black')\n",
        "    # inserisco l'ellisse\n",
        "    cov = gmm.covariances_[i]\n",
        "    v, w = np.linalg.eigh(cov)\n",
        "    angle = np.arctan2(w[0][1], w[0][0])\n",
        "    angle = 180 * angle / np.pi\n",
        "    v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
        "    ell = Ellipse(xy=gmm.means_[i], width=v[0], height=v[1], angle=180 + angle, color='black', alpha=0.5)\n",
        "    plt.gca().add_patch(ell)\n",
        "    # peso del cluster\n",
        "    plt.text(gmm.means_[i][0], gmm.means_[i][1], '%.2f' % gmm.weights_[i], fontsize=12)\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FCM algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# eseguo la clusterizzazione FCM usando torch\n",
        "\n",
        "# importo da matplotlib le linee\n",
        "from matplotlib.lines import Line2D\n",
        "import torch\n",
        "# setto il device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# con kmeans stabilisco i centroidi iniziali\n",
        "kmeans = KMeans(n_clusters=N, init='k-means++', max_iter=1000)\n",
        "kmeans.fit(fused_data)\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "# calcolo la matrice delle distanze a 2 a 2 tra dati e centroidi\n",
        "data_torch = torch.tensor(fused_data, device=device)\n",
        "centroids = torch.tensor(centroids, device=device)\n",
        "m = 2\n",
        "\n",
        "for i in range(10000):\n",
        "    distances = torch.cdist(data_torch, centroids) ** (2/(m-1))\n",
        "    # calcolo la matrice di membership\n",
        "    U = 1 / (distances * torch.sum(1 / distances, dim=1, keepdim=True))\n",
        "\n",
        "    # calcolo i nuovi centroidi\n",
        "    Um = U ** m\n",
        "    centroids = torch.matmul(Um.T, data_torch) / torch.sum(Um, dim=0, keepdim=True).T\n",
        "\n",
        "# plotto i risultati:\n",
        "# i centroidi sono indicati con una x e i dat9i con dei cerchi\n",
        "# il colore di un cluster \u00e8 dettato dal label stimato con fcm (argmax)\n",
        "# il valore di tale collegamente \u00e8 indicato con una linea tanto pi\u00f9 chiara quanto pi\u00f9 \u00e8 basso\n",
        "plt.figure(figsize=(10, 10))\n",
        "labels = torch.argmax(U, dim=1)\n",
        "\n",
        "# passo a numpy per poter usare le funzioni di matplotlib\n",
        "labels = labels.cpu().numpy()\n",
        "centroids = centroids.cpu().numpy()\n",
        "U = U.cpu().numpy()\n",
        "for i in range(N):\n",
        "    plt.scatter(fused_data[labels==i][:,0], fused_data[labels==i][:,1], label='Cluster %d' % i)\n",
        "    plt.scatter(centroids[i,0], centroids[i,1], marker='x', s=100, c='black')\n",
        "for j in range(len(fused_data)):\n",
        "    middle = 1./len(centroids)\n",
        "    for i in range(N):\n",
        "        if U[j,i] >= middle:\n",
        "            line = Line2D(\n",
        "                [fused_data[j,0], centroids[i,0]],\n",
        "                [fused_data[j,1], centroids[i,1]],\n",
        "                alpha=U[j,i],\n",
        "                color='black',\n",
        "            )\n",
        "            plt.gca().add_line(line)\n",
        "    \n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cleaning and gray scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# leggo un'immagine non preprocessata\n",
        "img = Image.open(\"data/db/cutted_set/Author2/Author2_0001_01.png\").convert(\"L\")\n",
        "\n",
        "# mostro l'immagine a schermo\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Studio la densit\u00e0 dei grigi nell'immagine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# la converto in un array numpy\n",
        "img_array = np.array(img, dtype=np.float32)/256.0\n",
        "\n",
        "# mostro un grafico con la densit\u00e0 in scala di grigi\n",
        "# sull'ascisse un valore tra 0 e 1, sull'ordinata il numero di pixel con quel valore\n",
        "plt.hist(img_array.flatten(), bins=256, color='black', density=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# taglio i colori in base al loro valore rispetto un threshold\n",
        "threshold = 0.25\n",
        "img_array_cut = np.zeros_like(img_array)\n",
        "img_array_cut[img_array < threshold] = 0\n",
        "img_array_cut[img_array >= threshold] = 1\n",
        "\n",
        "# mostro l'immagine a schermo\n",
        "plt.imshow(img_array_cut, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# eseguo una clusterizzazione kmeans su tutti i valori tra 0 e 1 con n_centroids\n",
        "n_centroids = 8\n",
        "img_flat = img_array.reshape(-1, 1)\n",
        "kmeans = KMeans(n_clusters=n_centroids, init='k-means++', max_iter=1000)\n",
        "kmeans.fit(img_flat)\n",
        "labels = kmeans.predict(img_flat)\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "# controllo che il numero di iterazioni non abbia superato max_iter\n",
        "if kmeans.n_iter_ == kmeans.max_iter:\n",
        "    print('KMeans non ha convergenza')\n",
        "\n",
        "# riodino i centroidi e i labels in ordine crescente\n",
        "order = np.argsort(centroids.flatten())\n",
        "centroids = centroids[order]\n",
        "new_labels = np.zeros_like(labels)\n",
        "for i, o in enumerate(order):\n",
        "    new_labels[labels == o] = i\n",
        "labels = new_labels\n",
        "\n",
        "# Normalize labels to range [0, 1]\n",
        "normalized_labels = labels / labels.max()\n",
        "\n",
        "# Create a colormap\n",
        "cmap = plt.get_cmap('viridis')\n",
        "\n",
        "# Plot histogram for each cluster\n",
        "hist, bin_edges = np.histogram(img_array.flatten(), bins=256, density=False)\n",
        "for i in range(n_centroids):\n",
        "    cluster_data = img_flat[labels == i]\n",
        "    cluster_hist, _ = np.histogram(\n",
        "        cluster_data,\n",
        "        bins=bin_edges,\n",
        "        density=False\n",
        "    )\n",
        "    plt.hist(\n",
        "        bin_edges[:-1],\n",
        "        bins=bin_edges,\n",
        "        weights=cluster_hist / hist.sum() * 256,\n",
        "        color=cmap(i / n_centroids),\n",
        "        alpha=0.5,\n",
        "    )\n",
        "\n",
        "# Add vertical lines for centroids\n",
        "for c in centroids:\n",
        "    plt.axvline(c, color='blue')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ricostruisco l'immagine originale usando i centroidi\n",
        "img_reconstructed = centroids[labels].reshape(img_array.shape)\n",
        "\n",
        "# mostro l'immagine ricostruita\n",
        "plt.imshow(img_reconstructed, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# nell'immagine faccio s\u00ec che i pixel del cluster k-esimo siano colorati di rosso\n",
        "\n",
        "# cluster scelto\n",
        "for k in range(n_centroids):\n",
        "    # creo un'immagine vuota\n",
        "    img_colored = np.zeros(img_array.shape + (3,))\n",
        "    # coloro i pixel del cluster k-esimo di rosso\n",
        "    img_colored_flat = img_colored.reshape(-1, 3)\n",
        "    img_colored_flat[labels == k] = [1, 0, 0]\n",
        "    img_colored = img_colored_flat.reshape(img_array.shape + (3,))\n",
        "\n",
        "    # riproduco l'immagine\n",
        "    plt.imshow(img_colored)\n",
        "    plt.title('Cluster %d' % k)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# normalizzo l'immagine affinch\u00e9 solo i claster da A a B siano visibili (con valori tra 0 e 1)\n",
        "\n",
        "# scritte in 14-20/64\n",
        "\n",
        "A = 0\n",
        "B = 5\n",
        "# cerco il colore del pixel dentro il cluster A di valore minimo\n",
        "min_A = img_flat[labels == A].min()\n",
        "max_B = img_flat[labels == B].max()\n",
        "img_normalized = (img_array - min_A) / (max_B - min_A)\n",
        "# taglio i valori < 0 a 0 e i valori > 1 a 1\n",
        "img_normalized[img_normalized < 0] = 0\n",
        "img_normalized[img_normalized > 1] = 1\n",
        "\n",
        "# salvo l'immagine come png\n",
        "img_normalized = Image.fromarray(np.uint8(img_normalized*255))\n",
        "img_normalized.save('data/out/normalized.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Distanza tra distribuzioni"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# le due distribuzioni prese in esame sono due normali con varianza 1 e media -1 e 1\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "A_1 = torch.randn(1_000, 2, device=device) + torch.tensor([-2, 0], device=device)\n",
        "A_2 = torch.randn(2_000, 2, device=device) * 2 + torch.tensor([4, 0], device=device)\n",
        "A_3 = torch.randn(5_000, 2, device=device) * 0.5 + torch.tensor([0, 4], device=device)\n",
        "A_noise = torch.rand(100, 2, device=device) * 20 - 10\n",
        "# concateno i dati\n",
        "A = torch.cat([A_1, A_2, A_3, A_noise], dim=0)\n",
        "w_A = torch.ones(A.shape[0], device=device)/A.shape[0]\n",
        "\n",
        "B_1 = torch.randn(3_000, 2, device=device) * torch.tensor([0.5, 2], device=device) + torch.tensor([-1, 0], device=device)\n",
        "B_2 = torch.randn(3_000, 2, device=device) + torch.tensor([4, 0], device=device)\n",
        "B_3 = torch.randn(3_000, 2, device=device) * 0.5 + torch.tensor([0, -4], device=device)\n",
        "B_noise = torch.rand(200, 2, device=device) * 20 - 10\n",
        "# concateno i dati\n",
        "B = torch.cat([B_1, B_2, B_3, B_noise], dim=0)\n",
        "w_B = torch.ones(B.shape[0], device=device)/B.shape[0]\n",
        "\n",
        "# plotto i dati in 3d\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.scatter(A[:, 0].cpu(), A[:, 1].cpu(), label='A', alpha=0.5, s=2, color='red')\n",
        "plt.scatter(B[:, 0].cpu(), B[:, 1].cpu(), label='B', alpha=0.5, s=2, color='green')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# eseguo una clusterizzazione kmeans sulla fusione dei dati considerando i pesi\n",
        "fused_d = torch.cat([A, B])\n",
        "fused_w = torch.cat([w_A, w_B])\n",
        "n_clusters = 256\n",
        "\n",
        "fused_d = fused_d.view(-1, fused_d.shape[-1])\n",
        "kmeans = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=1000)\n",
        "\n",
        "fit = kmeans.fit(fused_d.cpu().numpy(), sample_weight=fused_w.cpu().numpy())\n",
        "\n",
        "centers = torch.from_numpy(fit.cluster_centers_).to(device=device)\n",
        "\n",
        "# plot dei centroidi (o neri) assieme alla distribuzione dei dati (scatter blu)\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.scatter(fused_d[:, 0].cpu(), fused_d[:, 1].cpu(), s=2, alpha=0.5, color='blue', label='Data')\n",
        "plt.scatter(centers[:, 0].cpu(), centers[:, 1].cpu(), s=30, color='black', marker='o', label='Centroids')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# uso centroids come initial centroids per fcm\n",
        "iter = 10\n",
        "fcm_centers = centers.clone()\n",
        "for i in range(iter):\n",
        "    distances = torch.cdist(fused_d, fcm_centers) ** 2\n",
        "    \n",
        "    # eseguo operazioni distinte su ogni riga di distances:\n",
        "    # se la riga contiene uno 0 allora setto 1 dove ci sono 0 e 0 altrove\n",
        "    # altrimenti calcolo la membership\n",
        "    special_rows = torch.any(distances == 0, dim=1, keepdim=True)\n",
        "    min_values = torch.min(distances, dim=1)[0]\n",
        "    U = torch.where(special_rows, \n",
        "        distances != 0, # if row contains 0, set 1 where 0 and 0 elsewhere\n",
        "        min_values[:,None] / distances, # else calculate membership\n",
        "    )\n",
        "    U = (U / U.sum(dim=1, keepdim=True))**2\n",
        "    fcm_centers = torch.matmul(U.T, fused_d) / torch.sum(U, dim=0, keepdim=True).T\n",
        "\n",
        "centers = fcm_centers.clone()\n",
        "# plot dei centroidi (o neri) assieme alla distribuzione dei dati (scatter blu)\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.scatter(fused_d[:, 0].cpu(), fused_d[:, 1].cpu(), s=2, alpha=0.5, color='blue', label='Data')\n",
        "plt.scatter(centers[:, 0].cpu(), centers[:, 1].cpu(), s=4, color='black', marker='o', label='Centroids')\n",
        "# aggiungo le linee di membership, se la membership \u00e8 superiore a 1/n_clusters inserisco una linea\n",
        "indices = torch.where(U >= 1./n_clusters)\n",
        "for i in range(len(indices[0])):\n",
        "    plt.plot(\n",
        "        [fused_d[indices[0][i], 0].cpu(), centers[indices[1][i], 0].cpu()],\n",
        "        [fused_d[indices[0][i], 1].cpu(), centers[indices[1][i], 1].cpu()],\n",
        "        color='black', alpha=U[indices[0][i], indices[1][i]].cpu().item()\n",
        "    )\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib.patches import Circle\n",
        "from matplotlib import cm\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "# se si usa kmeans U[i,j] = 1 se il punto i \u00e8 nel cluster j altrimenti 0\n",
        "labels = kmeans.predict(fused_d.cpu().numpy())\n",
        "U = torch.zeros(fused_d.shape[0], n_clusters, device=device)\n",
        "for i in range(fused_d.shape[0]):\n",
        "    U[i, labels[i]] = 1\n",
        "\n",
        "# definisco la misura dei cluster\n",
        "distances = torch.cdist(fused_d, centers) ** 2\n",
        "mu = (torch.einsum('ij,ij->j', U, distances) / torch.sum(U, dim=0))**(fused_d.shape[1]/2)\n",
        "# calcolo il peso di A e B sui cluster\n",
        "omega_A = torch.mean(U[:A.shape[0], :], dim=0)  # A \u00e8 il primo cluster\n",
        "omega_B = torch.mean(U[A.shape[0]:, :], dim=0)  # B \u00e8 il secondo cluster\n",
        "# calcolo i rapporti tra i pesi su ogni cluster\n",
        "r = torch.min(omega_A, omega_B) / torch.max(omega_A, omega_B)\n",
        "\n",
        "# plotto lo spazio di misura usato usando mu(c)**(1/fused_d.shape[1]) come raggio del cluster c\n",
        "\n",
        "# colormap\n",
        "colors = [(1, 0, 0), (0, 0, 1), (0, 1, 0)]\n",
        "n_bins = 256  # numero di intervalli nella colormap\n",
        "cmap_name = 'membership_colormap'\n",
        "my_cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N=n_bins)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "ax.scatter(fused_d[:, 0].cpu(), fused_d[:, 1].cpu(), s=4, alpha=0.4, color='blue')\n",
        "for i in range(n_clusters):\n",
        "    s = (omega_B[i] - omega_A[i])/(omega_B[i] + omega_A[i])\n",
        "    circle = Circle(\n",
        "        centers[i].cpu(),\n",
        "        mu[i].cpu()**(1/fused_d.shape[1]),\n",
        "        color=my_cmap(s.cpu()),\n",
        "        alpha=0.8)\n",
        "    ax.add_patch(circle)\n",
        "\n",
        "# inserisco la mappa di colori\n",
        "# Crea manualmente la colorbar\n",
        "norm = plt.Normalize(vmin=0, vmax=1)\n",
        "sm = cm.ScalarMappable(cmap=my_cmap, norm=norm)\n",
        "sm.set_array([])\n",
        "cbar = fig.colorbar(sm, ax=ax)  # Associa la colorbar all'asse 'ax'\n",
        "cbar.set_label('membership')\n",
        "cbar.set_ticks([0, 1])  # Imposta i tick manualmente\n",
        "cbar.set_ticklabels(['A', 'B'])  # Imposta le etichette dei tick\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Indice di Jaccard\n",
        "# computo D_A come la membership dei centroidi in A e D_B come la membership dei centroidi in B\n",
        "D_A = torch.max(U[:A.shape[0], :], dim=0)[0]\n",
        "D_B = torch.max(U[A.shape[0]:, :], dim=0)[0]\n",
        "# computo la cardinalit\u00e0 dell'unione e dell'intersezione\n",
        "card_inter = torch.sum(torch.min(D_A, D_B))\n",
        "card_union = torch.sum(torch.max(D_A, D_B))\n",
        "# computo l'indice di Jaccard\n",
        "J = card_inter / card_union\n",
        "print(\"Cardinalit\u00e0 di D_A: \", torch.sum(D_A))\n",
        "print(\"Cardinalit\u00e0 di D_B: \", torch.sum(D_B))\n",
        "print(\"Cardinalit\u00e0 dell'intersezione: \", card_inter)\n",
        "print(\"Cardinalit\u00e0 dell'unione: \", card_union)\n",
        "print(\"Indice di Jaccard: \", J)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# calcoliamo la distanza tra A e B\n",
        "integral = (((r - 1)/(r + 1))**2 @ mu)/(torch.sum(mu))\n",
        "reguliser = (1+J)**(-1)\n",
        "distance = integral * reguliser\n",
        "\n",
        "print(\"Integrale: \", integral)\n",
        "print(\"Regolarizzatore: \", reguliser)\n",
        "print(\"Distanza tra A e B: \", distance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plotto lo spazio di misura ottenuto:\n",
        "# evidenzio i cluster con un grafico a barre\n",
        "# ogni barra ha un'altezza proporzionale al peso del cluster e un ampiezza proporzionale alla misura\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Circle\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# aggiungo gli scatter fused_d in blu\n",
        "plt.scatter(fused_d[:, 0].cpu(), fused_d[:, 1].cpu(), color='blue', alpha=0.5, s=2)\n",
        "\n",
        "for i in range(n_clusters):\n",
        "    # creo una sfera con raggio proporzionale alla misura\n",
        "    # il suo colore dipende da weights ed \u00e8 indicato con color\n",
        "    circle = Circle(\n",
        "        centers[i].cpu().numpy(),\n",
        "        measure[i].item()**(1/fused_d.shape[1]),\n",
        "        color=(1-weights[i].item(), 0, weights[i].item()),\n",
        "        alpha=0.8,\n",
        "    )\n",
        "    # aggiungo il rettangolo al grafico\n",
        "    plt.gca().add_patch(circle)\n",
        "\n",
        "\n",
        "plt.xlim(-10, 10)\n",
        "plt.ylim(-10, 10)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fit di A e B su siffatta clusterizzazione\n",
        "labels_A = fit.predict(A.cpu().numpy().reshape(-1, fused_d.shape[1]))\n",
        "labels_B = fit.predict(B.cpu().numpy().reshape(-1, fused_d.shape[1]))\n",
        "\n",
        "# densit\u00e0 di probabilit\u00e0 di A e B sui cluster\n",
        "p_A = torch.zeros(n_clusters, device=device)\n",
        "p_B = torch.zeros(n_clusters, device=device)\n",
        "for i in range(n_clusters):\n",
        "    p_A[i] = torch.sum(w_A[labels_A == i])\n",
        "    p_B[i] = torch.sum(w_B[labels_B == i])\n",
        "p_A /= torch.sum(p_A)\n",
        "p_B /= torch.sum(p_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plotto le densit\u00e0\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Circle\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "# colormap\n",
        "colors = [(1, 0, 0), (0.5, 0.5, 1), (0, 1, 0)]\n",
        "n_bins = 256  # numero di intervalli nella colormap\n",
        "cmap_name = 'membership_colormap'\n",
        "my_cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N=n_bins)\n",
        "\n",
        "fig, ax = plt.subplots()  # Crea una figura e un asse\n",
        "for i in range(n_clusters):\n",
        "    if measure[i] == 0:\n",
        "        # metto una X blu per i cluster vuoti\n",
        "        ax.scatter(centers[i,0].item(), centers[i,1].item(), marker='x', color='blue')\n",
        "    else:\n",
        "        # calcolo l'addendo senza elevare al quadrato\n",
        "        s = ((p_A[i] - p_B[i])/(p_A[i] + p_B[i]))\n",
        "        s = (s + 1)/2\n",
        "        # creo un cerchio per il cluster i-esimo\n",
        "        circ = Circle(\n",
        "            centers[i].cpu(),\n",
        "            measure[i].item()**(1/fused_d.shape[1]),\n",
        "            color=my_cmap(s.cpu()),\n",
        "            alpha=1.0,\n",
        "        )\n",
        "        # aggiungo il rettangolo al grafico\n",
        "        ax.add_patch(circ)\n",
        "\n",
        "# inserisco la mappa di colori\n",
        "# Crea manualmente la colorbar\n",
        "norm = plt.Normalize(vmin=0, vmax=1)\n",
        "sm = cm.ScalarMappable(cmap=my_cmap, norm=norm)\n",
        "sm.set_array([])\n",
        "cbar = fig.colorbar(sm, ax=ax)  # Associa la colorbar all'asse 'ax'\n",
        "cbar.set_label('membership')\n",
        "\n",
        "plt.xlim(-6, 12)\n",
        "plt.ylim(-9, 8)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ne calcolo la distanza\n",
        "D_A = p_A > 0\n",
        "D_B = p_B > 0\n",
        "\n",
        "integral = torch.where(D_A | D_B, measure * ((p_A-p_B)/(p_A+p_B))**2, torch.zeros(n_clusters, device=device)).sum() / measure[D_A | D_B].sum()\n",
        "Jaccard_index = measure[D_A & D_B].sum() / measure[D_A | D_B].sum()\n",
        "\n",
        "distance = (1 + Jaccard_index)**(-1) * integral\n",
        "print(distance.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## controprova senza clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nodes_perdim = 32\n",
        "\n",
        "# centri dei cluster sono una meshgrid\n",
        "centers = torch.meshgrid([torch.linspace(-6, 12, nodes_perdim), torch.linspace(-9, 8, nodes_perdim)])\n",
        "x_radius = 9 / nodes_perdim\n",
        "y_radius = 8.5 / nodes_perdim\n",
        "\n",
        "# la misura \u00e8 unica e uguale per tutti quindi non serve\n",
        "# calcolo le densit\u00e0 di probabilit\u00e0 di A e B sui cluster\n",
        "p_A = torch.zeros((nodes_perdim,nodes_perdim), device=device)\n",
        "p_B = torch.zeros((nodes_perdim,nodes_perdim), device=device)\n",
        "for i in range(nodes_perdim):\n",
        "    for j in range(nodes_perdim):\n",
        "        # conto quanti punti di A e B sono nel cluster i-esimo, ossia nel range [centers[i]-radius, centers[i]+radius]\n",
        "        p_A[i,j] = torch.sum(\n",
        "            (A[:,0] >= centers[0][i,j]-x_radius) & (A[:,0] < centers[0][i,j]+x_radius) &\n",
        "            (A[:,1] >= centers[1][i,j]-y_radius) & (A[:,1] < centers[1][i,j]+y_radius)\n",
        "        )\n",
        "        p_B[i,j] = torch.sum(\n",
        "            (B[:,0] >= centers[0][i,j]-x_radius) & (B[:,0] < centers[0][i,j]+x_radius) &\n",
        "            (B[:,1] >= centers[1][i,j]-y_radius) & (B[:,1] < centers[1][i,j]+y_radius)\n",
        "        )\n",
        "p_A /= torch.sum(p_A)\n",
        "p_B /= torch.sum(p_B)\n",
        "\n",
        "p_A = p_A.view(-1)\n",
        "p_B = p_B.view(-1)\n",
        "\n",
        "# calcolo le distanze\n",
        "D_A = p_A > 0\n",
        "D_B = p_B > 0\n",
        "integral = torch.where(D_A | D_B, ((p_A-p_B)/(p_A+p_B))**2, torch.zeros(nodes_perdim*nodes_perdim, device=device)).sum() / torch.count_nonzero(D_A | D_B)\n",
        "Jaccard_index = torch.count_nonzero(D_A & D_B) / torch.count_nonzero(D_A | D_B)\n",
        "\n",
        "distance = (1 + Jaccard_index)**(-1) * integral\n",
        "print(distance.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FFT 2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "def my_map(X, Y):\n",
        "    return 2*torch.cos(2*math.pi*(2*X + 3*Y) + 3) + 0.8*torch.cos(2*math.pi*(X + 5*Y) + 2) + torch.cos(2*math.pi*(7*X + 5*Y)) + torch.randn(X.shape)\n",
        "\n",
        "# genero X,Y in una matrice 32x16 con valori da 0\n",
        "X, Y = torch.meshgrid([torch.linspace(0, 1, 64), torch.linspace(0, 1, 32)])\n",
        "\n",
        "Z = my_map(X,Y)\n",
        "\n",
        "# calcolo la trasformata di fourier 2d con fft\n",
        "Z_fft = torch.fft.fft2(Z)\n",
        "\n",
        "# plotting\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# creo 2 plot disposti orizzontalmente\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
        "\n",
        "# in ax[0] mostro la mappa Z\n",
        "ax[0].imshow(Z.cpu().numpy(), cmap='viridis')\n",
        "\n",
        "# in ax[1] mostro la mappa Z_fft\n",
        "ax[1].imshow(torch.abs(Z_fft).cpu().numpy(), cmap='viridis')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "L = [{0}]\n",
        "F = [{1}]\n",
        "\n",
        "index = 0\n",
        "for i in range(1,10000):\n",
        "    for j in range(len(L)-1, -1, -1):\n",
        "        # controllo se L[j-1] si interseca con F[index] se non si interseca siamo a cavallo\n",
        "        if not (L[j] & F[index]) and not i in F[j]:\n",
        "            # i due insiemi non si intersecano\n",
        "            L[j].add(i)\n",
        "            F[j].add(i+1)\n",
        "            F[j].add(i-1)\n",
        "            index = j\n",
        "            break\n",
        "    else:\n",
        "        # non esiste alcun j valido quindi incremento\n",
        "        L.append({i})\n",
        "        F.append({i+1, i-1})\n",
        "        index = -1\n",
        "\n",
        "# trasformo in lista ordinata ogni insieme in L\n",
        "for i in range(len(L)):\n",
        "    L[i] = sorted(list(L[i]))\n",
        "\n",
        "for l in L:\n",
        "    print(l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PreProcessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prendo due immagini e le preprocesso\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "from source.packages import cleaner\n",
        "import logging\n",
        "\n",
        "cleaner.fft(\n",
        "    logging.getLogger(),    \n",
        "    \"data/db/cutted_set/Author3\",\n",
        "    \"data/.out\",\n",
        "    False,\n",
        "    0.001,\n",
        "    'cuda'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# open image\n",
        "img = Image.open(\"data/db/cutted_set/Author3/Author3_0001_01.png\").convert(\"L\")\n",
        "# plot dell'immagine\n",
        "plt.subplot(2,2,1)\n",
        "plt.title(\"my image\", cmap='gray')\n",
        "plt.imshow(img)\n",
        "plt.subplot(2,2,2)\n",
        "plt.title(\"my image\")\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compare Stability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-08 22:23:23,787 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:23:23,787 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:23:23,787 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:23:23,789 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:23:23,789 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:23:23,789 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:23:23,790 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:23:23,790 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:23:23,790 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:23:23,791 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:23:23,791 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:23:23,791 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:23:23,792 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:23:23,792 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:23:23,792 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:23:23,793 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:23:23,793 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:23:23,793 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:23:23,794 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:23:23,794 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:23:23,794 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:23:32,736 - root - INFO - fuzzy parameters: 1.423508644104004 shared centroids, 1.7179267406463623 total centroids\n",
            "2024-12-08 22:23:32,736 - root - INFO - fuzzy parameters: 1.423508644104004 shared centroids, 1.7179267406463623 total centroids\n",
            "2024-12-08 22:23:32,736 - root - INFO - fuzzy parameters: 1.423508644104004 shared centroids, 1.7179267406463623 total centroids\n",
            "2024-12-08 22:23:32,737 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.09239926189184189\n",
            "2024-12-08 22:23:32,737 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.09239926189184189\n",
            "2024-12-08 22:23:32,737 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.09239926189184189\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.09239926189184189\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-08 22:25:00,002 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:25:00,002 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:25:00,002 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:25:00,003 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:25:00,003 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:25:00,003 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:25:00,005 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:25:00,005 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:25:00,005 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:25:00,006 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:25:00,006 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:25:00,006 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:25:00,006 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:25:00,006 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:25:00,006 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:25:00,007 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:25:00,007 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:25:00,007 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:25:00,009 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:25:00,009 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:25:00,009 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:25:10,047 - root - INFO - fuzzy parameters: 2.274333953857422 shared centroids, 2.554133892059326 total centroids\n",
            "2024-12-08 22:25:10,047 - root - INFO - fuzzy parameters: 2.274333953857422 shared centroids, 2.554133892059326 total centroids\n",
            "2024-12-08 22:25:10,047 - root - INFO - fuzzy parameters: 2.274333953857422 shared centroids, 2.554133892059326 total centroids\n",
            "2024-12-08 22:25:10,049 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.0889066532254219\n",
            "2024-12-08 22:25:10,049 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.0889066532254219\n",
            "2024-12-08 22:25:10,049 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.0889066532254219\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0889066532254219\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-08 22:26:39,588 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:26:39,588 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:26:39,588 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:26:39,590 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:26:39,590 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:26:39,590 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:26:39,590 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:26:39,590 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:26:39,590 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:26:39,592 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:26:39,592 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:26:39,592 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:26:39,593 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:26:39,593 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:26:39,593 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:26:39,594 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:26:39,594 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:26:39,594 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:26:39,595 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:26:39,595 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:26:39,595 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:26:48,922 - root - INFO - fuzzy parameters: 2.304764747619629 shared centroids, 2.5927541255950928 total centroids\n",
            "2024-12-08 22:26:48,922 - root - INFO - fuzzy parameters: 2.304764747619629 shared centroids, 2.5927541255950928 total centroids\n",
            "2024-12-08 22:26:48,922 - root - INFO - fuzzy parameters: 2.304764747619629 shared centroids, 2.5927541255950928 total centroids\n",
            "2024-12-08 22:26:48,924 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.08926311135292053\n",
            "2024-12-08 22:26:48,924 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.08926311135292053\n",
            "2024-12-08 22:26:48,924 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.08926311135292053\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.08926311135292053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-08 22:28:15,389 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:28:15,389 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:28:15,389 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:28:15,390 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:28:15,390 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:28:15,390 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:28:15,391 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:28:15,391 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:28:15,391 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:28:15,392 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:28:15,392 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:28:15,392 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:28:15,393 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:28:15,393 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:28:15,393 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:28:15,394 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:28:15,394 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:28:15,394 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:28:15,395 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:28:15,395 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:28:15,395 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:28:24,520 - root - INFO - fuzzy parameters: 1.793642520904541 shared centroids, 2.140170097351074 total centroids\n",
            "2024-12-08 22:28:24,520 - root - INFO - fuzzy parameters: 1.793642520904541 shared centroids, 2.140170097351074 total centroids\n",
            "2024-12-08 22:28:24,520 - root - INFO - fuzzy parameters: 1.793642520904541 shared centroids, 2.140170097351074 total centroids\n",
            "2024-12-08 22:28:24,521 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.09229911863803864\n",
            "2024-12-08 22:28:24,521 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.09229911863803864\n",
            "2024-12-08 22:28:24,521 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.09229911863803864\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.09229911863803864\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-08 22:29:46,852 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:29:46,852 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:29:46,852 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:29:46,853 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:29:46,853 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:29:46,853 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:29:46,854 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:29:46,854 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:29:46,854 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:29:46,855 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:29:46,855 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:29:46,855 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:29:46,856 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:29:46,856 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:29:46,856 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:29:46,857 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:29:46,857 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:29:46,857 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:29:46,857 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:29:46,857 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:29:46,857 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:29:56,660 - root - INFO - fuzzy parameters: 2.2981607913970947 shared centroids, 2.6041126251220703 total centroids\n",
            "2024-12-08 22:29:56,660 - root - INFO - fuzzy parameters: 2.2981607913970947 shared centroids, 2.6041126251220703 total centroids\n",
            "2024-12-08 22:29:56,660 - root - INFO - fuzzy parameters: 2.2981607913970947 shared centroids, 2.6041126251220703 total centroids\n",
            "2024-12-08 22:29:56,662 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.08934266865253448\n",
            "2024-12-08 22:29:56,662 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.08934266865253448\n",
            "2024-12-08 22:29:56,662 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.08934266865253448\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.08934266865253448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-08 22:31:21,825 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:31:21,825 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:31:21,825 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:31:21,826 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:31:21,826 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:31:21,826 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:31:21,827 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:31:21,827 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:31:21,827 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:31:21,829 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:31:21,829 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:31:21,829 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:31:21,830 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:31:21,830 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:31:21,830 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:31:21,831 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:31:21,831 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:31:21,831 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:31:21,832 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:31:21,832 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:31:21,832 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:31:31,000 - root - INFO - fuzzy parameters: 1.7960617542266846 shared centroids, 2.1482157707214355 total centroids\n",
            "2024-12-08 22:31:31,000 - root - INFO - fuzzy parameters: 1.7960617542266846 shared centroids, 2.1482157707214355 total centroids\n",
            "2024-12-08 22:31:31,000 - root - INFO - fuzzy parameters: 1.7960617542266846 shared centroids, 2.1482157707214355 total centroids\n",
            "2024-12-08 22:31:31,002 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.09126268327236176\n",
            "2024-12-08 22:31:31,002 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.09126268327236176\n",
            "2024-12-08 22:31:31,002 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.09126268327236176\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.09126268327236176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-08 22:32:53,072 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:32:53,072 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:32:53,072 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:32:53,073 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:32:53,073 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:32:53,073 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:32:53,074 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:32:53,074 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:32:53,074 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:32:53,075 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:32:53,075 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:32:53,075 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:32:53,076 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:32:53,076 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:32:53,076 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:32:53,076 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:32:53,076 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:32:53,076 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:32:53,077 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:32:53,077 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:32:53,077 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:33:02,232 - root - INFO - fuzzy parameters: 2.31195068359375 shared centroids, 2.678784132003784 total centroids\n",
            "2024-12-08 22:33:02,232 - root - INFO - fuzzy parameters: 2.31195068359375 shared centroids, 2.678784132003784 total centroids\n",
            "2024-12-08 22:33:02,232 - root - INFO - fuzzy parameters: 2.31195068359375 shared centroids, 2.678784132003784 total centroids\n",
            "2024-12-08 22:33:02,234 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.09047120064496994\n",
            "2024-12-08 22:33:02,234 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.09047120064496994\n",
            "2024-12-08 22:33:02,234 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.09047120064496994\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.09047120064496994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-08 22:34:19,577 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:34:19,577 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:34:19,577 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:34:19,578 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:34:19,578 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:34:19,578 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:34:19,579 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:34:19,579 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:34:19,579 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:34:19,581 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:34:19,581 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:34:19,581 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:34:19,582 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:34:19,582 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:34:19,582 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:34:19,583 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:34:19,583 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:34:19,583 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:34:19,585 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:34:19,585 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:34:19,585 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:34:29,748 - root - INFO - fuzzy parameters: 2.2895147800445557 shared centroids, 2.6879525184631348 total centroids\n",
            "2024-12-08 22:34:29,748 - root - INFO - fuzzy parameters: 2.2895147800445557 shared centroids, 2.6879525184631348 total centroids\n",
            "2024-12-08 22:34:29,748 - root - INFO - fuzzy parameters: 2.2895147800445557 shared centroids, 2.6879525184631348 total centroids\n",
            "2024-12-08 22:34:29,750 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.08988629281520844\n",
            "2024-12-08 22:34:29,750 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.08988629281520844\n",
            "2024-12-08 22:34:29,750 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.08988629281520844\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.08988629281520844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-08 22:35:54,627 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:35:54,627 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:35:54,627 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:35:54,627 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:35:54,627 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:35:54,627 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:35:54,629 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:35:54,629 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:35:54,629 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:35:54,630 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:35:54,630 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:35:54,630 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:35:54,630 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:35:54,630 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:35:54,630 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:35:54,631 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:35:54,631 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:35:54,631 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:35:54,632 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:35:54,632 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:35:54,632 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:36:03,918 - root - INFO - fuzzy parameters: 2.466672658920288 shared centroids, 2.8222408294677734 total centroids\n",
            "2024-12-08 22:36:03,918 - root - INFO - fuzzy parameters: 2.466672658920288 shared centroids, 2.8222408294677734 total centroids\n",
            "2024-12-08 22:36:03,918 - root - INFO - fuzzy parameters: 2.466672658920288 shared centroids, 2.8222408294677734 total centroids\n",
            "2024-12-08 22:36:03,920 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.08934333175420761\n",
            "2024-12-08 22:36:03,920 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.08934333175420761\n",
            "2024-12-08 22:36:03,920 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.08934333175420761\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.08934333175420761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-08 22:37:27,869 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:37:27,869 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:37:27,869 - root - INFO - Total memory: 4086169600\n",
            "2024-12-08 22:37:27,870 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:37:27,870 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:37:27,870 - root - INFO - Reserved memory: 234881024\n",
            "2024-12-08 22:37:27,871 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:37:27,871 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:37:27,871 - root - INFO - Allocated memory: 8519680\n",
            "2024-12-08 22:37:27,871 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:37:27,871 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:37:27,871 - root - INFO - Free memory: 3851288576\n",
            "2024-12-08 22:37:27,872 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:37:27,872 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:37:27,872 - root - INFO - number of dimensions: 16\n",
            "2024-12-08 22:37:27,873 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:37:27,873 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:37:27,873 - root - INFO - number of centroids: 1024\n",
            "2024-12-08 22:37:27,874 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:37:27,874 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:37:27,874 - root - INFO - Batch size: 10000\n",
            "2024-12-08 22:37:36,828 - root - INFO - fuzzy parameters: 1.7862588167190552 shared centroids, 2.175665855407715 total centroids\n",
            "2024-12-08 22:37:36,828 - root - INFO - fuzzy parameters: 1.7862588167190552 shared centroids, 2.175665855407715 total centroids\n",
            "2024-12-08 22:37:36,828 - root - INFO - fuzzy parameters: 1.7862588167190552 shared centroids, 2.175665855407715 total centroids\n",
            "2024-12-08 22:37:36,829 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.0917317271232605\n",
            "2024-12-08 22:37:36,829 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.0917317271232605\n",
            "2024-12-08 22:37:36,829 - root - INFO - Computed distance between data/.out/synthetized/Author1/Author1_0046_08.png, data/.out/synthetized/Author2/Author2_0003_03.png: 0.0917317271232605\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0917317271232605\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from source.packages import distance, clustering\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "console_handler = logging.StreamHandler()\n",
        "console_handler.setLevel(logging.INFO)\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "console_handler.setFormatter(formatter)\n",
        "logger.addHandler(console_handler)\n",
        "n_tiles = 4\n",
        "fcm_tollerance = 0.2\n",
        "n_clusters = 1_024\n",
        "\n",
        "# carico 2 sintesi\n",
        "for _ in range(10):\n",
        "    work_1 = 'data/.out/synthetized/Author1/Author1_0046_08.png'\n",
        "    work_2 = 'data/.out/synthetized/Author2/Author2_0003_03.png'\n",
        "\n",
        "    # open synthesis\n",
        "    with open(work_1, \"br\") as f:\n",
        "        values = f.read()\n",
        "    synth_1 = (\n",
        "        np.frombuffer(values, dtype=np.uint8)\n",
        "        .reshape(-1, 4 * 4)\n",
        "        .astype(np.float32)\n",
        "        / 255.0\n",
        "    )\n",
        "    # open synthesis\n",
        "    with open(work_2, \"br\") as f:\n",
        "        values = f.read()\n",
        "    synth_2 = (\n",
        "        np.frombuffer(values, dtype=np.uint8)\n",
        "        .reshape(-1, 4 * 4)\n",
        "        .astype(np.float32)\n",
        "        / 255.0\n",
        "    )\n",
        "    synth_merge = np.vstack((synth_1, synth_2))\n",
        "    with open(r\"./temp/synth_merge\", \"bw\") as f:\n",
        "        f.write(synth_merge.tobytes())\n",
        "    # estraggo un campione di n_clusters righe da synth_merge\n",
        "    synth_sample = np.random.choice(\n",
        "        synth_merge.shape[0], n_clusters, replace=False\n",
        "    )\n",
        "    synth_sample = synth_merge[synth_sample]\n",
        "    # aggiungo del noise\n",
        "    synth_sample += np.random.normal(0, 0.01, synth_sample.shape)\n",
        "    # salvo il campione in un file temporaneo come float32 binario (i centroidi iniziali)\n",
        "    with open(r\"./temp/synth_sample\", \"bw\") as f:\n",
        "        f.write(synth_sample.tobytes())\n",
        "\n",
        "    # costruisco il campione dei pesi, tutti uguali per i rispettivi synth\n",
        "    synth_weights = np.ones((synth_merge.shape[0]), dtype=np.float32)\n",
        "    # mi chiedo quale sia la sintesi con pi\u00f9 dati\n",
        "    synth_weights[: synth_1.shape[0]] = (\n",
        "        np.ones((synth_1.shape[0]), dtype=np.float32)\n",
        "        / synth_1.shape[0]\n",
        "    )\n",
        "    synth_weights[synth_1.shape[0] :] = (\n",
        "        np.ones((synth_2.shape[0]), dtype=np.float32)\n",
        "        / synth_2.shape[0]\n",
        "    )\n",
        "    # salvo i pesi in un file temporaneo come float32 binario\n",
        "    with open(r\"./temp/synth_weights\", \"bw\") as f:\n",
        "        f.write(synth_weights.tobytes())\n",
        "\n",
        "    # libero la ram (fondamentale per evitare memory error)\n",
        "    del values\n",
        "    del synth_1\n",
        "    del synth_2\n",
        "    del synth_merge  # ora presente in ./temp/synth_merge\n",
        "    del synth_sample  # ora presente in ./temp/synth_sample\n",
        "    del synth_weights  # ora presente in ./temp/synth_weights\n",
        "\n",
        "    # eseguo il clustering fcm\n",
        "    try:\n",
        "        clustering.fcm(\n",
        "            logger,\n",
        "            r\"./temp/synth_merge\",\n",
        "            r\"./temp/synth_weights\",\n",
        "            r\"./temp/synth_sample\",\n",
        "            r\"./temp/centroids\",\n",
        "            n_tiles * n_tiles,\n",
        "            fcm_tollerance,\n",
        "            r\"./logs/fcm.log\",\n",
        "        )\n",
        "    except SyntaxError:\n",
        "        logger.critical(\"Implementation error!\")\n",
        "        exit()\n",
        "    except ValueError:\n",
        "        logger.error(\"Unvalid inputs\")\n",
        "        exit()\n",
        "    except Exception:\n",
        "        logger.error(\"Unexpected error\")\n",
        "        exit()\n",
        "\n",
        "    # uso i centroidi in \"./temp/centroids\" per calcolare la distanza tra i due synth\n",
        "    # load data\n",
        "    with open(work_1, \"br\") as f:\n",
        "        values = f.read()\n",
        "    synth_1 = (\n",
        "        np.frombuffer(values, dtype=np.uint8)\n",
        "        .reshape(-1, n_tiles * n_tiles)\n",
        "        .astype(np.float32)\n",
        "        / 255.0\n",
        "    )\n",
        "    with open(work_2, \"br\") as f:\n",
        "        values = f.read()\n",
        "    synth_2 = (\n",
        "        np.frombuffer(values, dtype=np.uint8)\n",
        "        .reshape(-1, n_tiles * n_tiles)\n",
        "        .astype(np.float32)\n",
        "        / 255.0\n",
        "    )\n",
        "    weights_1 = (\n",
        "        np.ones((synth_1.shape[0]), dtype=np.float32)\n",
        "        / synth_1.shape[0]\n",
        "    )\n",
        "    weights_2 = (\n",
        "        np.ones((synth_2.shape[0]), dtype=np.float32)\n",
        "        / synth_2.shape[0]\n",
        "    )\n",
        "    with open(r\"./temp/centroids\", \"br\") as f:\n",
        "        values = f.read()\n",
        "    centroids = np.frombuffer(values, dtype=np.float32).reshape(\n",
        "        n_clusters, n_tiles * n_tiles\n",
        "    )\n",
        "    # compute distance\n",
        "    try:\n",
        "        dist = distance.compute_distance(\n",
        "            logger,\n",
        "            synth_1,\n",
        "            synth_2,\n",
        "            weights_1,\n",
        "            weights_2,\n",
        "            centroids,\n",
        "        )\n",
        "    except SyntaxError:\n",
        "        logger.critical(\"Implementation error!\")\n",
        "        exit()\n",
        "    except ValueError:\n",
        "        logger.error(\"Unvalid inputs\")\n",
        "        exit()\n",
        "    except Exception:\n",
        "        logger.error(\"Unexpected error\")\n",
        "        exit()\n",
        "    else:\n",
        "        logger.info(f\"Computed distance between {work_1}, {work_2}: {dist}\")\n",
        "    print(dist)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
