{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import colorsys\n",
        "from math import pi, tanh\n",
        "\n",
        "def complex_to_rgb(c: torch.Tensor):\n",
        "    hue = c.angle().item() / (2 * pi)\n",
        "    saturation = 1\n",
        "    light = 0.9-0.8*tanh(c.abs().item())\n",
        "    return colorsys.hls_to_rgb(hue, light, saturation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# leggo l'immagine\n",
        "image_path = 'db/cutted_set/Author1/Author1_0025_02.png'\n",
        "\n",
        "# carico l'immagine e la passo a torch\n",
        "image = Image.open(image_path).convert('L')\n",
        "image_torch = torch.from_numpy(np.array(image)).to('cuda')\n",
        "image_torch_mean = image_torch.mean(dtype=torch.float32)\n",
        "image_torch = image_torch - image_torch_mean\n",
        "image_torch = image_torch / image_torch.var()**0.5\n",
        "\n",
        "# analisi di fourier usando fft2d\n",
        "image_fft = torch.fft.fft2(image_torch, norm='ortho').to('cpu')\n",
        "\n",
        "# devo ideare una scala di colore che dato un numero complesso mi dia un colore\n",
        "image_fft_rgb = torch.zeros(image_fft.shape + (3,))\n",
        "for i in range(image_fft.shape[0]):\n",
        "    for j in range(image_fft.shape[1]):\n",
        "        image_fft_rgb[i, j] = torch.tensor(complex_to_rgb(image_fft[i, j]))\n",
        "\n",
        "# visualizzo le due immagini a confronto in una grande figura\n",
        "plt.figure(figsize=(2*8, 1*8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image_torch.to('cpu'), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Original Image')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(image_fft_rgb.to('cpu'), vmin=0, vmax=1)\n",
        "plt.axis('off')\n",
        "plt.title('Fourier Transform')\n",
        "plt.savefig('fft.png', dpi=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rilevo i picchi di magnitudine\n",
        "p = 0.1/100  # percentile\n",
        "image_fft_abs = image_fft.flatten().abs()\n",
        "image_fft_abs_sort = torch.sort(image_fft_abs, descending=True)\n",
        "threshold = image_fft_abs_sort.values[int(p * image_fft_abs.numel())]\n",
        "image_fft_abs_thresholded = image_fft_abs <= threshold\n",
        "\n",
        "# cambio tipo in float\n",
        "image_fft_abs_thresholded = image_fft_abs_thresholded.to(torch.float32)\n",
        "\n",
        "# visualizzo i picchi\n",
        "plt.figure()\n",
        "plt.imshow(image_fft_abs_thresholded.reshape(image_fft.shape), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title(f'Peaks using percentile {p*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# annullo i picchi\n",
        "image_fft_new = image_fft * image_fft_abs_thresholded.reshape(image_fft.shape)\n",
        "\n",
        "# ricostruisco l'immagine\n",
        "image_reconstructed = torch.fft.ifft2(image_fft_new, norm='ortho').real\n",
        "image_reconstructed = (image_reconstructed - image_reconstructed.min()) / (image_reconstructed.max() - image_reconstructed.min())\n",
        "\n",
        "# visualizzo l'immagine ricostruita\n",
        "plt.figure()\n",
        "plt.imshow(image_reconstructed, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Reconstructed Image with percentile threshold 0.02%')\n",
        "plt.savefig('reconstructed.png', dpi=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mostro l'istogramma dei valori di grigio di image_torch\n",
        "plt.figure()\n",
        "image_reconstructed = (image_reconstructed - image_reconstructed.min()) / (image_reconstructed.max() - image_reconstructed.min())\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(image_reconstructed.to('cpu').flatten(), bins=256, density=True)\n",
        "plt.title('Reconstructed Image Histogram')\n",
        "plt.xlabel('Gray Value')\n",
        "plt.ylabel('Density')\n",
        "#plt.subplot(1,2,1)\n",
        "plt.subplot(1,2,2)\n",
        "image_normalized = (np.array(image) - np.array(image).min()) / (np.array(image).max() - np.array(image).min())\n",
        "plt.hist(image_normalized.flatten(), bins=256, density=True)\n",
        "plt.title('Original Image Histogram')\n",
        "plt.xlabel('Gray Value')\n",
        "plt.savefig(\"diagrams.png\", dpi=600)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# imposto un threshold e mostro nell'immagine quali pixel superano il threshold\n",
        "min,max = 0.2, 0.8\n",
        "image_torch = torch.from_numpy(np.array(image)) / 255.0\n",
        "# bianco qui -> bianco originale (dello sfondo) allora ok\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.imshow(image_torch > max, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Thresholded Image')\n",
        "# nero qui -> nero originale (delle scritte) allora ok\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.imshow(image_torch >= min, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Thresholded Image')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mostro nel diagramma i valori di grigio dell'immagine originale evidenziando in rosso quelli inferiori a min e in verde quelli superiori a max\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(image_torch.flatten(), bins=256, density=True)\n",
        "plt.title('Original Image Histogram')\n",
        "plt.xlabel('Gray Value')\n",
        "plt.ylabel('Density')\n",
        "plt.axvline(min, color='red', label='Handwriting threshold')\n",
        "plt.axvline(max, color='green', label='Background threshold')\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "# conto quanti pixel in image_torch sono inferiori a min\n",
        "b_cnt = torch.count_nonzero(image_torch <= min) / image_torch.numel()\n",
        "# conto quanti pixel in image_torch sono superiori a max\n",
        "w_cnt = torch.count_nonzero(image_torch >= max) / image_torch.numel()\n",
        "# determino i trashold per il clamp\n",
        "h_b = torch.quantile(image_reconstructed, b_cnt)\n",
        "h_w = torch.quantile(image_reconstructed, 1 - w_cnt)\n",
        "plt.hist(image_reconstructed.flatten(), bins=256, density=True)\n",
        "plt.title('Original Image Histogram')\n",
        "plt.xlabel('Gray Value')\n",
        "plt.ylabel('Density')\n",
        "plt.axvline(h_b, color='red', label='Handwriting threshold')\n",
        "plt.axvline(h_w, color='green', label='Background threshold')\n",
        "plt.legend()\n",
        "plt.savefig('thresholded_histogram.png', dpi=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# normalize image\n",
        "min,max = 0.2, 0.8\n",
        "# conto quanti pixel in image_torch sono inferiori a min\n",
        "b_cnt = torch.count_nonzero(image_torch <= min) / image_torch.numel()\n",
        "# conto quanti pixel in image_torch sono superiori a max\n",
        "w_cnt = torch.count_nonzero(image_torch >= max) / image_torch.numel()\n",
        "# determino i trashold per il clamp\n",
        "h_b = torch.quantile(image_reconstructed, b_cnt)\n",
        "h_w = torch.quantile(image_reconstructed, 1 - w_cnt)\n",
        "\n",
        "\n",
        "image_new = (image_reconstructed - h_b) / (h_w - h_b)\n",
        "image_new = torch.clamp(image_new, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# visualizzo l'immagine ricostruita\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.imshow(image_reconstructed, cmap='gray', vmin=0, vmax=1)\n",
        "plt.axis('off')\n",
        "plt.title('Reconstructed Image without normalisation')\n",
        "\n",
        "# mostro il plot dei grigi presenti\n",
        "plt.subplot(2, 2, 2, aspect=0.05)\n",
        "plt.hist(image_reconstructed.flatten(), bins=256, density=True)\n",
        "plt.title('Grayscale density')\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.imshow(image_new, cmap='gray', vmin=0, vmax=1)\n",
        "plt.axis('off')\n",
        "plt.title('Reconstructed Image with normalisation')\n",
        "plt.subplot(2, 2, 4, aspect=0.003)\n",
        "plt.hist(image_new.flatten(), bins=256, density=True)\n",
        "plt.title('Grayscale density')\n",
        "\n",
        "plt.savefig('first_reconstruct.png', dpi=1200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy\n",
        "\n",
        "# load synthesis image\n",
        "synth_path = r'.out/synthetized/Author2/Author2_0003_01.png'\n",
        "\n",
        "with open(synth_path, \"br\") as f:\n",
        "    values = f.read()\n",
        "synth_1 = (\n",
        "    numpy.frombuffer(values, dtype=numpy.uint8)\n",
        "    .reshape(-1, 4 * 4)\n",
        "    .astype(numpy.float32)\n",
        "    / 255.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# apply a PCA to the image\n",
        "import sklearn.decomposition\n",
        "import sklearn.manifold\n",
        "\n",
        "pca = sklearn.decomposition.PCA(n_components=6)\n",
        "pca.fit(synth_1)\n",
        "synth_1_pca = pca.transform(synth_1)\n",
        "indices = numpy.random.choice(synth_1_pca.shape[0], 10_000, replace=False)\n",
        "synth_1_sample = synth_1_pca[indices]\n",
        "#tsne = sklearn.manifold.TSNE(n_components=3, verbose=1, max_iter=3000, n_jobs=8)\n",
        "#synth_1_tsne = tsne.fit_transform(synth_1_sample)\n",
        "synth_1_tsne = synth_1_sample.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot 3d of data\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "# load the data into a pandas dataframe\n",
        "# data_3d = np.load('/home/stefano/Desktop/ao.npy')\n",
        "\n",
        "data = synth_1_tsne.copy()\n",
        "df = pd.DataFrame(data[:,:3], columns=['x', 'y', 'z'])\n",
        "\n",
        "# nel data frame scrivo anche a quale indice appartiene il dato\n",
        "df['Index'] = indices\n",
        "\n",
        "# assegno un colore in base le \n",
        "df['r'] = data[:, 3]\n",
        "df['g'] = data[:, 4]\n",
        "df['b'] = data[:, 5]\n",
        "# normalizzo tra 0,1\n",
        "df['r'] = (df['r'] - df['r'].min()) / (df['r'].max() - df['r'].min())\n",
        "df['g'] = (df['g'] - df['g'].min()) / (df['g'].max() - df['g'].min())\n",
        "df['b'] = (df['b'] - df['b'].min()) / (df['b'].max() - df['b'].min())\n",
        "# ottengo RGB da r,g,b\n",
        "df['color'] = df.apply(lambda x: [x['r'], x['g'], x['b']], axis=1)\n",
        "\n",
        "df['color_hex'] = df['color'].apply(mcolors.rgb2hex)\n",
        "\n",
        "# quando la freccia si posa su un punto voglio che si mostri anche il campo 'Index' del dataframe\n",
        "fig = px.scatter_3d(\n",
        "    df, \n",
        "    x='x', \n",
        "    y='y', \n",
        "    z='z',\n",
        "    opacity=1.0,\n",
        "    width=1000,  # Imposta la larghezza del grafico\n",
        "    height=800,  # Imposta l'altezza del grafico\n",
        "    hover_data=['color_hex', 'Index'],  # Mostra l'indice del punto quando ci si posa sopra\n",
        ")\n",
        "\n",
        "fig.update_traces(marker=dict(color=df['color_hex'], size=5))\n",
        "\n",
        "# Mostra il grafico interattivo\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "# plot 2d of an image\n",
        "index = 3222433\n",
        "\n",
        "# load the tile\n",
        "tile = synth_1[index].reshape(4, 4)\n",
        "\n",
        "# plot the tile\n",
        "plt.figure()\n",
        "plt.imshow(tile, cmap='gray', vmin=0, vmax=1)\n",
        "plt.axis('off')\n",
        "plt.savefig('tile.png', dpi=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RESULTS EXPLORATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26902\n",
            "         Author2  Author4  Author1  Author3\n",
            "Author2      2.0      0.0      5.0      0.0\n",
            "Author4      2.0      1.0      4.0      0.0\n",
            "Author1      2.0      1.0     34.0      1.0\n",
            "Author3      0.0      0.0      1.0      2.0\n",
            "\n",
            "Author Author2\n",
            "False Positives: 0.6666666666666667\n",
            "False Negatives: 0.7142857142857143\n",
            "Entropy: 0.5982695885852573 (max: 5.545177444479562)\n",
            "\n",
            "Author Author4\n",
            "False Positives: 0.5\n",
            "False Negatives: 0.8571428571428572\n",
            "Entropy: 0.9556998911125343 (max: 5.545177444479562)\n",
            "\n",
            "Author Author1\n",
            "False Positives: 0.2272727272727273\n",
            "False Negatives: 0.10526315789473684\n",
            "Entropy: 0.44594004925087577 (max: 5.545177444479562)\n",
            "\n",
            "Author Author3\n",
            "False Positives: 0.33333333333333337\n",
            "False Negatives: 0.33333333333333337\n",
            "Entropy: 0.6365141682948129 (max: 5.545177444479562)\n"
          ]
        }
      ],
      "source": [
        "# definisco una funzione che data path detecta l'autore\n",
        "import os\n",
        "def author_detect(path:str):\n",
        "    # l'autore \u00e8 il nome della cartella contenente il file\n",
        "    author = os.path.basename(os.path.dirname(path))\n",
        "    return author\n",
        "\n",
        "# carico il file csv distances.csv\n",
        "import pandas as pd\n",
        "import numpy\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# il file csv \u00e8 una matrice di float con righe e colonne indicizzate con una path\n",
        "df = pd.read_csv('distances.csv', index_col=0)\n",
        "\n",
        "distances = df.to_numpy()\n",
        "\n",
        "# print no-nan values quantity\n",
        "print((numpy.count_nonzero(~numpy.isnan(distances)) - 420)//2)\n",
        "\n",
        "# creo una tabella dove inserisco i risultati:\n",
        "# la riga dell'autore i-esimo e la colonna dell'autore j-esimo contiene il numero di opere di i che sono state classificate come opere di j\n",
        "\n",
        "# creo una lista di autori\n",
        "authors = df.index.map(author_detect).unique()\n",
        "\n",
        "# creo una tabella vuota\n",
        "table = pd.DataFrame(numpy.zeros((len(authors), len(authors))), index=authors, columns=authors)\n",
        "\n",
        "deep = 1\n",
        "for i in range(len(df)):\n",
        "    # estraggo le distanze della i-esima opera\n",
        "    work_distances = distances[i].copy()\n",
        "    # trasformo i nan in inf\n",
        "    work_distances = numpy.nan_to_num(work_distances, nan=float('inf'))\n",
        "    # trasformo il confronto con se stesso in inf\n",
        "    work_distances[i] = float('inf')\n",
        "    # trovo l'indice delle deep opere pi\u00f9 vicine\n",
        "    nearest_work = numpy.argpartition(work_distances, deep)[:deep]\n",
        "    \n",
        "    # per ogni autore conto il numero di opere in questa lista\n",
        "    # vettore di infiniti\n",
        "    score = numpy.full(len(authors), numpy.inf)\n",
        "    counter = numpy.zeros(len(authors))\n",
        "    for j in range(deep):\n",
        "        # ricavo l'autore dell'opera di indice nearest_work[j]\n",
        "        nearest_author = author_detect(df.index[nearest_work[j]])\n",
        "        # incremento lo score con la distanza\n",
        "        # se ho infinito annullo\n",
        "        if score[authors.get_loc(nearest_author)] == numpy.inf:\n",
        "            score[authors.get_loc(nearest_author)] = 0\n",
        "        score[authors.get_loc(nearest_author)] += distances[i, nearest_work[j]]\n",
        "        # incremento il contatore\n",
        "        counter[authors.get_loc(nearest_author)] += 1\n",
        "    \n",
        "    # ricavo l'autore dell'opera stessa\n",
        "    author = author_detect(df.index[i])\n",
        "    # trovo l'autore dell'opera pi\u00f9 vicina\n",
        "    score = score / counter\n",
        "    nearest_author = authors[score.argmin()]\n",
        "    # incremento il contatore dell'autore i-esimo e dell'autore pi\u00f9 vicino con il rapporto del numero di opere considerate\n",
        "    # per l'opera i-esima conto il numero di opere che sono state comparate (non sono inf o nan)\n",
        "    num_of_works = numpy.count_nonzero(work_distances != numpy.inf)\n",
        "    table.at[author, nearest_author] += 1 if num_of_works > 200 else 0\n",
        "\n",
        "print(table)\n",
        "\n",
        "# per ogni autore calcolo i veri positivi e i veri negativi\n",
        "for i in range(len(authors)):\n",
        "    fp = 1 - table.iat[i, i] / table.iloc[:, i].sum()\n",
        "    fn = 1 - table.iat[i, i] / table.iloc[i].sum()\n",
        "    print('')\n",
        "    print(f'Author {authors[i]}')\n",
        "    print(f'False Positives: {fp}')\n",
        "    print(f'False Negatives: {fn}')\n",
        "    p = (table.iloc[i, :] / table.iloc[i, :].sum()).values\n",
        "    p = p[p != 0]\n",
        "    entropy = -numpy.log(p) @ p\n",
        "    print(f'Entropy: {entropy} (max: {numpy.log(len(authors))*len(authors)})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ogni opera ha permesso di stabilire un'attribuzione\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# per ogni opera quindi stabilisco la sua capacit\u00e0 di attribuzione: attribuzioni corrette / attribuzioni totali\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mdf\u001b[49m)):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# estraggo l'autore dell'opera\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     author \u001b[38;5;241m=\u001b[39m author_detect(df\u001b[38;5;241m.\u001b[39mindex[i])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# comparo tutte le opere con l'opera i-esima\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "# ogni opera ha permesso di stabilire un'attribuzione\n",
        "# per ogni opera quindi stabilisco la sua capacit\u00e0 di attribuzione: attribuzioni corrette / attribuzioni totali\n",
        "for i in range(len(df)):\n",
        "    # estraggo l'autore dell'opera\n",
        "    author = author_detect(df.index[i])\n",
        "    # comparo tutte le opere con l'opera i-esima\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# carico l'immagine fraseGauss.png\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# converto in bit 0, 1\n",
        "image = Image.open('fraseGauss_rotated.png').convert('L')\n",
        "# aumento il contrasto\n",
        "#image = image.point(lambda p: (p / 255)**5 * 255)\n",
        "#image.save('fraseGauss.png')\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(image, cmap='gray', vmin=0, vmax=256)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# uso SVD per comprimere l'immagine\n",
        "import numpy as np\n",
        "\n",
        "image_np = np.array(image)\n",
        "U, S, V = np.linalg.svd(image_np, full_matrices=False)\n",
        "\n",
        "# comprimo l'immagine\n",
        "k=20\n",
        "compressed_image = U[:, k:] @ np.diag(S[k:]) @ V[k:, :]\n",
        "plt.figure()\n",
        "plt.imshow(compressed_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.imsave('first_pattern.png', compressed_image, dpi=600, cmap='gray')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
